{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da400e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from scipy.signal import medfilt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bd1dbde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7169 frames in directory\n",
      "Phase 1: Computing transforms...\n",
      "Processed 100/7169 frames\n",
      "Processed 200/7169 frames\n",
      "Processed 300/7169 frames\n",
      "Processed 400/7169 frames\n",
      "Processed 500/7169 frames\n",
      "Processed 600/7169 frames\n",
      "Processed 700/7169 frames\n",
      "Processed 800/7169 frames\n",
      "Processed 900/7169 frames\n",
      "Processed 1000/7169 frames\n",
      "Processed 1100/7169 frames\n",
      "Processed 1200/7169 frames\n",
      "Processed 1300/7169 frames\n",
      "Processed 1400/7169 frames\n",
      "Processed 1500/7169 frames\n",
      "Processed 1600/7169 frames\n",
      "Processed 1700/7169 frames\n",
      "Processed 1800/7169 frames\n",
      "Processed 1900/7169 frames\n",
      "Processed 2000/7169 frames\n",
      "Processed 2100/7169 frames\n",
      "Processed 2200/7169 frames\n",
      "Processed 2300/7169 frames\n",
      "Processed 2400/7169 frames\n",
      "Processed 2500/7169 frames\n",
      "Processed 2600/7169 frames\n",
      "Processed 2700/7169 frames\n",
      "Processed 2800/7169 frames\n",
      "Processed 2900/7169 frames\n",
      "Processed 3000/7169 frames\n",
      "Processed 3100/7169 frames\n",
      "Processed 3200/7169 frames\n",
      "Processed 3300/7169 frames\n",
      "Processed 3400/7169 frames\n",
      "Processed 3500/7169 frames\n",
      "Processed 3600/7169 frames\n",
      "Processed 3700/7169 frames\n",
      "Processed 3800/7169 frames\n",
      "Processed 3900/7169 frames\n",
      "Processed 4000/7169 frames\n",
      "Processed 4100/7169 frames\n",
      "Processed 4200/7169 frames\n",
      "Processed 4300/7169 frames\n",
      "Processed 4400/7169 frames\n",
      "Processed 4500/7169 frames\n",
      "Processed 4600/7169 frames\n",
      "Processed 4700/7169 frames\n",
      "Processed 4800/7169 frames\n",
      "Processed 4900/7169 frames\n",
      "Processed 5000/7169 frames\n",
      "Processed 5100/7169 frames\n",
      "Processed 5200/7169 frames\n",
      "Processed 5300/7169 frames\n",
      "Processed 5400/7169 frames\n",
      "Processed 5500/7169 frames\n",
      "Processed 5600/7169 frames\n",
      "Processed 5700/7169 frames\n",
      "Processed 5800/7169 frames\n",
      "Processed 5900/7169 frames\n",
      "Processed 6000/7169 frames\n",
      "Processed 6100/7169 frames\n",
      "Processed 6200/7169 frames\n",
      "Processed 6300/7169 frames\n",
      "Processed 6400/7169 frames\n",
      "Processed 6500/7169 frames\n",
      "Processed 6600/7169 frames\n",
      "Processed 6700/7169 frames\n",
      "Processed 6800/7169 frames\n",
      "Processed 6900/7169 frames\n",
      "Processed 7000/7169 frames\n",
      "Processed 7100/7169 frames\n",
      "Phase 2: Smoothing trajectory...\n",
      "Phase 3: Applying stabilization and writing video...\n",
      "Stabilized and wrote 100/7169 frames\n",
      "Stabilized and wrote 200/7169 frames\n",
      "Stabilized and wrote 300/7169 frames\n",
      "Stabilized and wrote 400/7169 frames\n",
      "Stabilized and wrote 500/7169 frames\n",
      "Stabilized and wrote 600/7169 frames\n",
      "Stabilized and wrote 700/7169 frames\n",
      "Stabilized and wrote 800/7169 frames\n",
      "Stabilized and wrote 900/7169 frames\n",
      "Stabilized and wrote 1000/7169 frames\n",
      "Stabilized and wrote 1100/7169 frames\n",
      "Stabilized and wrote 1200/7169 frames\n",
      "Stabilized and wrote 1300/7169 frames\n",
      "Stabilized and wrote 1400/7169 frames\n",
      "Stabilized and wrote 1500/7169 frames\n",
      "Stabilized and wrote 1600/7169 frames\n",
      "Stabilized and wrote 1700/7169 frames\n",
      "Stabilized and wrote 1800/7169 frames\n",
      "Stabilized and wrote 1900/7169 frames\n",
      "Stabilized and wrote 2000/7169 frames\n",
      "Stabilized and wrote 2100/7169 frames\n",
      "Stabilized and wrote 2200/7169 frames\n",
      "Stabilized and wrote 2300/7169 frames\n",
      "Stabilized and wrote 2400/7169 frames\n",
      "Stabilized and wrote 2500/7169 frames\n",
      "Stabilized and wrote 2600/7169 frames\n",
      "Stabilized and wrote 2700/7169 frames\n",
      "Stabilized and wrote 2800/7169 frames\n",
      "Stabilized and wrote 2900/7169 frames\n",
      "Stabilized and wrote 3000/7169 frames\n",
      "Stabilized and wrote 3100/7169 frames\n",
      "Stabilized and wrote 3200/7169 frames\n",
      "Stabilized and wrote 3300/7169 frames\n",
      "Stabilized and wrote 3400/7169 frames\n",
      "Stabilized and wrote 3500/7169 frames\n",
      "Stabilized and wrote 3600/7169 frames\n",
      "Stabilized and wrote 3700/7169 frames\n",
      "Stabilized and wrote 3800/7169 frames\n",
      "Stabilized and wrote 3900/7169 frames\n",
      "Stabilized and wrote 4000/7169 frames\n",
      "Stabilized and wrote 4100/7169 frames\n",
      "Stabilized and wrote 4200/7169 frames\n",
      "Stabilized and wrote 4300/7169 frames\n",
      "Stabilized and wrote 4400/7169 frames\n",
      "Stabilized and wrote 4500/7169 frames\n",
      "Stabilized and wrote 4600/7169 frames\n",
      "Stabilized and wrote 4700/7169 frames\n",
      "Stabilized and wrote 4800/7169 frames\n",
      "Stabilized and wrote 4900/7169 frames\n",
      "Stabilized and wrote 5000/7169 frames\n",
      "Stabilized and wrote 5100/7169 frames\n",
      "Stabilized and wrote 5200/7169 frames\n",
      "Stabilized and wrote 5300/7169 frames\n",
      "Stabilized and wrote 5400/7169 frames\n",
      "Stabilized and wrote 5500/7169 frames\n",
      "Stabilized and wrote 5600/7169 frames\n",
      "Stabilized and wrote 5700/7169 frames\n",
      "Stabilized and wrote 5800/7169 frames\n",
      "Stabilized and wrote 5900/7169 frames\n",
      "Stabilized and wrote 6000/7169 frames\n",
      "Stabilized and wrote 6100/7169 frames\n",
      "Stabilized and wrote 6200/7169 frames\n",
      "Stabilized and wrote 6300/7169 frames\n",
      "Stabilized and wrote 6400/7169 frames\n",
      "Stabilized and wrote 6500/7169 frames\n",
      "Stabilized and wrote 6600/7169 frames\n",
      "Stabilized and wrote 6700/7169 frames\n",
      "Stabilized and wrote 6800/7169 frames\n",
      "Stabilized and wrote 6900/7169 frames\n",
      "Stabilized and wrote 7000/7169 frames\n",
      "Stabilized and wrote 7100/7169 frames\n",
      "Stabilized video saved at: C:\\Users\\simar\\OneDrive\\Desktop\\Python_stabilization\\RegionBased_stabilized.mp4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def load_frames_from_directory(frames_path):\n",
    "    \"\"\"Load frames from directory in sorted order\"\"\"\n",
    "    frame_files = []\n",
    "    for filename in sorted(os.listdir(frames_path)):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "            frame_files.append(os.path.join(frames_path, filename))\n",
    "    return frame_files\n",
    "\n",
    "def detect_and_match_features_fast(img1, img2):\n",
    "    # FAST keypoints + ORB descriptors for speed and robustness\n",
    "    fast = cv2.FastFeatureDetector_create(threshold=60)\n",
    "    orb = cv2.ORB_create(nfeatures=1000)\n",
    "    kp1 = fast.detect(img1, None)\n",
    "    kp2 = fast.detect(img2, None)\n",
    "    kp1, des1 = orb.compute(img1, kp1)\n",
    "    kp2, des2 = orb.compute(img2, kp2)\n",
    "    if des1 is None or des2 is None:\n",
    "        return np.array([]), np.array([])\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(des1, des2)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "    if len(matches) < 4:\n",
    "        return np.array([]), np.array([])\n",
    "    good_matches = matches[:min(50, len(matches))]\n",
    "    pts1 = np.float32([kp1[m.queryIdx].pt for m in good_matches])\n",
    "    pts2 = np.float32([kp2[m.trainIdx].pt for m in good_matches])\n",
    "    return pts1, pts2\n",
    "\n",
    "def filter_motion_outliers(pts1, pts2):\n",
    "    motion_vectors = pts2 - pts1\n",
    "    motion_magnitudes = np.linalg.norm(motion_vectors, axis=1)\n",
    "    median_motion = np.median(motion_magnitudes)\n",
    "    mad = np.median(np.abs(motion_magnitudes - median_motion))\n",
    "    threshold = median_motion + 2 * mad\n",
    "    static_mask = motion_magnitudes < threshold\n",
    "    return pts1[static_mask], pts2[static_mask]\n",
    "\n",
    "def create_water_mask(frame):\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    lower_water = np.array([90, 0, 50])\n",
    "    upper_water = np.array([130, 100, 200])\n",
    "    water_mask = cv2.inRange(hsv, lower_water, upper_water)\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    water_mask = cv2.morphologyEx(water_mask, cv2.MORPH_CLOSE, kernel)\n",
    "    return water_mask\n",
    "\n",
    "def filter_features_by_region(pts1, pts2, frame):\n",
    "    water_mask = create_water_mask(frame)\n",
    "    valid_mask = []\n",
    "    for pt in pts1:\n",
    "        x, y = int(pt[0]), int(pt[1])\n",
    "        if 0 <= x < water_mask.shape[1] and 0 <= y < water_mask.shape[0]:\n",
    "            valid_mask.append(water_mask[y, x] == 0)\n",
    "        else:\n",
    "            valid_mask.append(True)\n",
    "    valid_mask = np.array(valid_mask)\n",
    "    return pts1[valid_mask], pts2[valid_mask]\n",
    "\n",
    "def estimate_homography(pts1, pts2):\n",
    "    if len(pts1) >= 4 and len(pts2) >= 4:\n",
    "        H, mask = cv2.findHomography(pts1, pts2, cv2.RANSAC, 5.0)\n",
    "        if H is None:\n",
    "            return np.eye(3)\n",
    "        return H\n",
    "    else:\n",
    "        return np.eye(3)\n",
    "\n",
    "def adaptive_trajectory_smoothing(trajectory, motion_threshold=10):\n",
    "    trajectory = np.array(trajectory)\n",
    "    smoothed = np.zeros_like(trajectory)\n",
    "    for i in range(trajectory.shape[1]):\n",
    "        component = trajectory[:, i]\n",
    "        motion_magnitude = np.abs(np.diff(component))\n",
    "        from scipy.signal import savgol_filter\n",
    "        if np.any(motion_magnitude > motion_threshold):\n",
    "            smoothed[:, i] = savgol_filter(component, window_length=5, polyorder=2)\n",
    "        else:\n",
    "            smoothed[:, i] = savgol_filter(component, window_length=15, polyorder=3)\n",
    "    return smoothed\n",
    "\n",
    "def improved_stabilization_from_frames(frames_path, output_path, fps=29.97):\n",
    "    \"\"\"\n",
    "    Stabilization using pre-extracted frames from directory\n",
    "    \"\"\"\n",
    "    # Load frame file paths\n",
    "    frame_files = load_frames_from_directory(frames_path)\n",
    "    total_frames = len(frame_files)\n",
    "    \n",
    "    if total_frames == 0:\n",
    "        print(\"Error: No frames found in directory\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {total_frames} frames in directory\")\n",
    "    \n",
    "    # Read first frame to get dimensions\n",
    "    first_frame = cv2.imread(frame_files[0])\n",
    "    if first_frame is None:\n",
    "        print(\"Error: Could not read first frame\")\n",
    "        return\n",
    "    \n",
    "    h, w = first_frame.shape[:2]\n",
    "    \n",
    "    # Setup output video\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (w, h))\n",
    "    \n",
    "    prev_gray = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "    transforms = []\n",
    "    trajectory = [np.eye(3)]\n",
    "    \n",
    "    print(\"Phase 1: Computing transforms...\")\n",
    "    \n",
    "    # Process frames from directory\n",
    "    for i in range(1, total_frames):\n",
    "        curr_frame = cv2.imread(frame_files[i])\n",
    "        if curr_frame is None:\n",
    "            print(f\"Warning: Could not read frame {i}\")\n",
    "            transforms.append(np.eye(3))\n",
    "            trajectory.append(trajectory[-1])\n",
    "            continue\n",
    "        \n",
    "        curr_gray = cv2.cvtColor(curr_frame, cv2.COLOR_BGR2GRAY)\n",
    "        pts1, pts2 = detect_and_match_features_fast(prev_gray, curr_gray)\n",
    "        \n",
    "        if len(pts1) > 0:\n",
    "            pts1, pts2 = filter_motion_outliers(pts1, pts2)\n",
    "        if len(pts1) > 0:\n",
    "            pts1, pts2 = filter_features_by_region(pts1, pts2, curr_frame)\n",
    "        \n",
    "        H = estimate_homography(pts1, pts2)\n",
    "        transforms.append(H)\n",
    "        trajectory.append(trajectory[-1] @ H)\n",
    "        prev_gray = curr_gray\n",
    "        \n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"Processed {i + 1}/{total_frames} frames\")\n",
    "    \n",
    "    print(\"Phase 2: Smoothing trajectory...\")\n",
    "    \n",
    "    # Extract parameters and smooth\n",
    "    params = []\n",
    "    for H in trajectory:\n",
    "        dx = H[0, 2]\n",
    "        dy = H[1, 2]\n",
    "        da = np.arctan2(H[1, 0], H[0, 0])\n",
    "        params.append([dx, dy, da])\n",
    "    \n",
    "    smoothed_params = adaptive_trajectory_smoothing(params, motion_threshold=15)\n",
    "    \n",
    "    # Calculate smoothed transforms\n",
    "    new_transforms = []\n",
    "    for i in range(len(smoothed_params)):\n",
    "        dx, dy, da = smoothed_params[i]\n",
    "        cos_a = np.cos(da)\n",
    "        sin_a = np.sin(da)\n",
    "        new_H = np.array([[cos_a, -sin_a, dx],\n",
    "                          [sin_a,  cos_a, dy],\n",
    "                          [0,      0,     1]], dtype=np.float32)\n",
    "        new_transforms.append(new_H)\n",
    "    \n",
    "    print(\"Phase 3: Applying stabilization and writing video...\")\n",
    "    \n",
    "    # Apply stabilization and write video\n",
    "    for i in range(total_frames):\n",
    "        frame = cv2.imread(frame_files[i])\n",
    "        if frame is None:\n",
    "            continue\n",
    "        \n",
    "        if i < len(new_transforms):\n",
    "            H = new_transforms[i]\n",
    "            if H is not None and not np.isnan(H).any() and not np.isinf(H).any():\n",
    "                try:\n",
    "                    frame_stabilized = cv2.warpPerspective(frame, H, (w, h), borderMode=cv2.BORDER_REFLECT)\n",
    "                except:\n",
    "                    frame_stabilized = frame\n",
    "            else:\n",
    "                frame_stabilized = frame\n",
    "        else:\n",
    "            frame_stabilized = frame\n",
    "        \n",
    "        out.write(frame_stabilized)\n",
    "        \n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"Stabilized and wrote {i + 1}/{total_frames} frames\")\n",
    "    \n",
    "    out.release()\n",
    "    print(f\"Stabilized video saved at: {output_path}\")\n",
    "\n",
    "# Usage with your extracted frames:\n",
    "frames_path = r\"C:\\Users\\simar\\OneDrive\\Desktop\\Python_stabilization\\unzipped_video\"\n",
    "output_path = r\"C:\\Users\\simar\\OneDrive\\Desktop\\Python_stabilization\\RegionBased_stabilized.mp4\"\n",
    "improved_stabilization_from_frames(frames_path, output_path, fps=29.97)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d172781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5681ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e90e8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
