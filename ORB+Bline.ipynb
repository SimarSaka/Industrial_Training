{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8199105f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping opencv-python as it is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\simar\\anaconda3\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\simar\\anaconda3\\lib\\site-packages (from opencv-contrib-python) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall opencv-python -y\n",
    "!pip install opencv-contrib-python\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "\n",
    "def detect_and_match_features_orb(img1, img2, orb):\n",
    "    kp1, des1 = orb.detectAndCompute(img1, None)\n",
    "    kp2, des2 = orb.detectAndCompute(img2, None)\n",
    "    if des1 is None or des2 is None:\n",
    "        return np.array([]), np.array([])\n",
    "    \n",
    "    # Use BFMatcher for ORB (binary descriptors)\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(des1, des2)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "    \n",
    "    if len(matches) < 4:\n",
    "        return np.array([]), np.array([])\n",
    "    \n",
    "    # Take best matches\n",
    "    good_matches = matches[:50]  # Top 50 matches\n",
    "    pts1 = np.float32([kp1[m.queryIdx].pt for m in good_matches])\n",
    "    pts2 = np.float32([kp2[m.trainIdx].pt for m in good_matches])\n",
    "    return pts1, pts2\n",
    "\n",
    "def estimate_homography(pts1, pts2):\n",
    "    if len(pts1) >= 4 and len(pts2) >= 4:\n",
    "        H, mask = cv2.findHomography(pts1, pts2, cv2.RANSAC, 5.0)\n",
    "        if H is None:\n",
    "            return np.eye(3)\n",
    "        return H\n",
    "    else:\n",
    "        return np.eye(3)\n",
    "\n",
    "def smooth_trajectory(trajectory, smoothing_factor=5):\n",
    "    trajectory = np.array(trajectory)\n",
    "    smoothed = []\n",
    "    for i in range(trajectory.shape[1]):\n",
    "        x = np.arange(trajectory.shape[0])\n",
    "        y = trajectory[:, i]\n",
    "        spl = UnivariateSpline(x, y, s=smoothing_factor)\n",
    "        smoothed.append(spl(x))\n",
    "    return np.array(smoothed).T\n",
    "\n",
    "def streaming_video_stabilization_orb(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Fast streaming video stabilization using ORB features\n",
    "    \"\"\"\n",
    "    # Open input video\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video\")\n",
    "        return\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    print(f\"Video info: {total_frames} frames, {w}x{h}, {fps:.2f} FPS\")\n",
    "    \n",
    "    # Setup output video\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (w, h))\n",
    "    \n",
    "    # Initialize ORB detector (much faster than SIFT)\n",
    "    orb = cv2.ORB_create(nfeatures=1000)\n",
    "    \n",
    "    # Read first frame\n",
    "    ret, prev_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Could not read first frame\")\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        return\n",
    "    \n",
    "    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Initialize lists to store trajectory and transforms\n",
    "    transforms = []\n",
    "    trajectory = [np.eye(3)]\n",
    "    \n",
    "    frame_count = 1\n",
    "    print(\"Phase 1: Computing transforms (using fast ORB)...\")\n",
    "    \n",
    "    # Phase 1: Compute all transforms\n",
    "    while True:\n",
    "        ret, curr_frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        curr_gray = cv2.cvtColor(curr_frame, cv2.COLOR_BGR2GRAY)\n",
    "        pts1, pts2 = detect_and_match_features_orb(prev_gray, curr_gray, orb)\n",
    "        H = estimate_homography(pts1, pts2)\n",
    "        transforms.append(H)\n",
    "        \n",
    "        # Build cumulative trajectory\n",
    "        trajectory.append(trajectory[-1] @ H)\n",
    "        \n",
    "        prev_gray = curr_gray\n",
    "        frame_count += 1\n",
    "        \n",
    "        if frame_count % 100 == 0:\n",
    "            print(f\"Processed {frame_count}/{total_frames} frames\")\n",
    "    \n",
    "    print(\"Phase 2: Smoothing trajectory...\")\n",
    "    \n",
    "    # Extract translation and rotation parameters\n",
    "    params = []\n",
    "    for H in trajectory:\n",
    "        dx = H[0, 2]\n",
    "        dy = H[1, 2]\n",
    "        da = np.arctan2(H[1, 0], H[0, 0])\n",
    "        params.append([dx, dy, da])\n",
    "    \n",
    "    # Smooth trajectory\n",
    "    smoothed_params = smooth_trajectory(params, smoothing_factor=10)\n",
    "    \n",
    "    # Calculate smoothed transforms\n",
    "    new_transforms = []\n",
    "    for i in range(len(smoothed_params)):\n",
    "        dx, dy, da = smoothed_params[i]\n",
    "        cos_a = np.cos(da)\n",
    "        sin_a = np.sin(da)\n",
    "        new_H = np.array([[cos_a, -sin_a, dx],\n",
    "                          [sin_a,  cos_a, dy],\n",
    "                          [0,      0,     1]], dtype=np.float32)\n",
    "        new_transforms.append(new_H)\n",
    "    \n",
    "    print(\"Phase 3: Applying stabilization and writing video...\")\n",
    "    \n",
    "    # Reset to beginning\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    \n",
    "    frame_idx = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Apply stabilization transform\n",
    "        if frame_idx < len(new_transforms):\n",
    "            H = new_transforms[frame_idx]\n",
    "            \n",
    "            # Validate transform matrix\n",
    "            if H is not None and not np.isnan(H).any() and not np.isinf(H).any():\n",
    "                try:\n",
    "                    frame_stabilized = cv2.warpPerspective(frame, H, (w, h), \n",
    "                                                         borderMode=cv2.BORDER_REFLECT)\n",
    "                except:\n",
    "                    frame_stabilized = frame\n",
    "            else:\n",
    "                frame_stabilized = frame\n",
    "        else:\n",
    "            frame_stabilized = frame\n",
    "        \n",
    "        # Write stabilized frame directly to output video\n",
    "        out.write(frame_stabilized)\n",
    "        \n",
    "        frame_idx += 1\n",
    "        if frame_idx % 100 == 0:\n",
    "            print(f\"Stabilized and wrote {frame_idx}/{total_frames} frames\")\n",
    "    \n",
    "    # Cleanup\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"Stabilized video saved at: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7be4f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video info: 7170 frames, 3840x2160, 29.97 FPS\n",
      "Phase 1: Computing transforms (using fast ORB)...\n",
      "Processed 100/7170 frames\n",
      "Processed 200/7170 frames\n",
      "Processed 300/7170 frames\n",
      "Processed 400/7170 frames\n",
      "Processed 500/7170 frames\n",
      "Processed 600/7170 frames\n",
      "Processed 700/7170 frames\n",
      "Processed 800/7170 frames\n",
      "Processed 900/7170 frames\n",
      "Processed 1000/7170 frames\n",
      "Processed 1100/7170 frames\n",
      "Processed 1200/7170 frames\n",
      "Processed 1300/7170 frames\n",
      "Processed 1400/7170 frames\n",
      "Processed 1500/7170 frames\n",
      "Processed 1600/7170 frames\n",
      "Processed 1700/7170 frames\n",
      "Processed 1800/7170 frames\n",
      "Processed 1900/7170 frames\n",
      "Processed 2000/7170 frames\n",
      "Processed 2100/7170 frames\n",
      "Processed 2200/7170 frames\n",
      "Processed 2300/7170 frames\n",
      "Processed 2400/7170 frames\n",
      "Processed 2500/7170 frames\n",
      "Processed 2600/7170 frames\n",
      "Processed 2700/7170 frames\n",
      "Processed 2800/7170 frames\n",
      "Processed 2900/7170 frames\n",
      "Processed 3000/7170 frames\n",
      "Processed 3100/7170 frames\n",
      "Processed 3200/7170 frames\n",
      "Processed 3300/7170 frames\n",
      "Processed 3400/7170 frames\n",
      "Processed 3500/7170 frames\n",
      "Processed 3600/7170 frames\n",
      "Processed 3700/7170 frames\n",
      "Processed 3800/7170 frames\n",
      "Processed 3900/7170 frames\n",
      "Processed 4000/7170 frames\n",
      "Processed 4100/7170 frames\n",
      "Processed 4200/7170 frames\n",
      "Processed 4300/7170 frames\n",
      "Processed 4400/7170 frames\n",
      "Processed 4500/7170 frames\n",
      "Processed 4600/7170 frames\n",
      "Processed 4700/7170 frames\n",
      "Processed 4800/7170 frames\n",
      "Processed 4900/7170 frames\n",
      "Processed 5000/7170 frames\n",
      "Processed 5100/7170 frames\n",
      "Processed 5200/7170 frames\n",
      "Processed 5300/7170 frames\n",
      "Processed 5400/7170 frames\n",
      "Processed 5500/7170 frames\n",
      "Processed 5600/7170 frames\n",
      "Processed 5700/7170 frames\n",
      "Processed 5800/7170 frames\n",
      "Processed 5900/7170 frames\n",
      "Processed 6000/7170 frames\n",
      "Processed 6100/7170 frames\n",
      "Processed 6200/7170 frames\n",
      "Processed 6300/7170 frames\n",
      "Processed 6400/7170 frames\n",
      "Processed 6500/7170 frames\n",
      "Processed 6600/7170 frames\n",
      "Processed 6700/7170 frames\n",
      "Processed 6800/7170 frames\n",
      "Processed 6900/7170 frames\n",
      "Processed 7000/7170 frames\n",
      "Processed 7100/7170 frames\n",
      "Phase 2: Smoothing trajectory...\n",
      "Phase 3: Applying stabilization and writing video...\n",
      "Stabilized and wrote 100/7170 frames\n",
      "Stabilized and wrote 200/7170 frames\n",
      "Stabilized and wrote 300/7170 frames\n",
      "Stabilized and wrote 400/7170 frames\n",
      "Stabilized and wrote 500/7170 frames\n",
      "Stabilized and wrote 600/7170 frames\n",
      "Stabilized and wrote 700/7170 frames\n",
      "Stabilized and wrote 800/7170 frames\n",
      "Stabilized and wrote 900/7170 frames\n",
      "Stabilized and wrote 1000/7170 frames\n",
      "Stabilized and wrote 1100/7170 frames\n",
      "Stabilized and wrote 1200/7170 frames\n",
      "Stabilized and wrote 1300/7170 frames\n",
      "Stabilized and wrote 1400/7170 frames\n",
      "Stabilized and wrote 1500/7170 frames\n",
      "Stabilized and wrote 1600/7170 frames\n",
      "Stabilized and wrote 1700/7170 frames\n",
      "Stabilized and wrote 1800/7170 frames\n",
      "Stabilized and wrote 1900/7170 frames\n",
      "Stabilized and wrote 2000/7170 frames\n",
      "Stabilized and wrote 2100/7170 frames\n",
      "Stabilized and wrote 2200/7170 frames\n",
      "Stabilized and wrote 2300/7170 frames\n",
      "Stabilized and wrote 2400/7170 frames\n",
      "Stabilized and wrote 2500/7170 frames\n",
      "Stabilized and wrote 2600/7170 frames\n",
      "Stabilized and wrote 2700/7170 frames\n",
      "Stabilized and wrote 2800/7170 frames\n",
      "Stabilized and wrote 2900/7170 frames\n",
      "Stabilized and wrote 3000/7170 frames\n",
      "Stabilized and wrote 3100/7170 frames\n",
      "Stabilized and wrote 3200/7170 frames\n",
      "Stabilized and wrote 3300/7170 frames\n",
      "Stabilized and wrote 3400/7170 frames\n",
      "Stabilized and wrote 3500/7170 frames\n",
      "Stabilized and wrote 3600/7170 frames\n",
      "Stabilized and wrote 3700/7170 frames\n",
      "Stabilized and wrote 3800/7170 frames\n",
      "Stabilized and wrote 3900/7170 frames\n",
      "Stabilized and wrote 4000/7170 frames\n",
      "Stabilized and wrote 4100/7170 frames\n",
      "Stabilized and wrote 4200/7170 frames\n",
      "Stabilized and wrote 4300/7170 frames\n",
      "Stabilized and wrote 4400/7170 frames\n",
      "Stabilized and wrote 4500/7170 frames\n",
      "Stabilized and wrote 4600/7170 frames\n",
      "Stabilized and wrote 4700/7170 frames\n",
      "Stabilized and wrote 4800/7170 frames\n",
      "Stabilized and wrote 4900/7170 frames\n",
      "Stabilized and wrote 5000/7170 frames\n",
      "Stabilized and wrote 5100/7170 frames\n",
      "Stabilized and wrote 5200/7170 frames\n",
      "Stabilized and wrote 5300/7170 frames\n",
      "Stabilized and wrote 5400/7170 frames\n",
      "Stabilized and wrote 5500/7170 frames\n",
      "Stabilized and wrote 5600/7170 frames\n",
      "Stabilized and wrote 5700/7170 frames\n",
      "Stabilized and wrote 5800/7170 frames\n",
      "Stabilized and wrote 5900/7170 frames\n",
      "Stabilized and wrote 6000/7170 frames\n",
      "Stabilized and wrote 6100/7170 frames\n",
      "Stabilized and wrote 6200/7170 frames\n",
      "Stabilized and wrote 6300/7170 frames\n",
      "Stabilized and wrote 6400/7170 frames\n",
      "Stabilized and wrote 6500/7170 frames\n",
      "Stabilized and wrote 6600/7170 frames\n",
      "Stabilized and wrote 6700/7170 frames\n",
      "Stabilized and wrote 6800/7170 frames\n",
      "Stabilized and wrote 6900/7170 frames\n",
      "Stabilized and wrote 7000/7170 frames\n",
      "Stabilized and wrote 7100/7170 frames\n",
      "Stabilized video saved at: BlineORB_stabilized_output.mp4\n"
     ]
    }
   ],
   "source": [
    "input_path = \"DJI_20250411113208_0019_D.MP4\"\n",
    "output_path = \"BlineORB_stabilized_output.mp4\"\n",
    "\n",
    "streaming_video_stabilization_orb(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da8d149",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddb4f46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c748522",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
