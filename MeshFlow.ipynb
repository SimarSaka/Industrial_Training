{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef1c36b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from scipy.signal import medfilt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec59e081",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estimating mesh flows:   0%|          | 4/7168 [00:01<48:14,  2.47it/s]\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\alloc.cpp:73: error: (-4:Insufficient memory) Failed to allocate 11059200 bytes in function 'cv::OutOfMemoryError'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 90\u001b[0m\n\u001b[0;32m     88\u001b[0m     mesh_flows\u001b[38;5;241m.\u001b[39mappend(mesh_flow)\n\u001b[0;32m     89\u001b[0m     prev_gray \u001b[38;5;241m=\u001b[39m curr_gray\n\u001b[1;32m---> 90\u001b[0m     prev_pts \u001b[38;5;241m=\u001b[39m detect_features(curr_gray)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# Step 2: Accumulate and smooth mesh flows\u001b[39;00m\n\u001b[0;32m     93\u001b[0m mesh_flows \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mzeros_like(mesh_flows[\u001b[38;5;241m0\u001b[39m])] \u001b[38;5;241m+\u001b[39m mesh_flows  \u001b[38;5;66;03m# First frame has zero motion\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 30\u001b[0m, in \u001b[0;36mdetect_features\u001b[1;34m(gray)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetect_features\u001b[39m(gray):\n\u001b[1;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mgoodFeaturesToTrack(gray, maxCorners\u001b[38;5;241m=\u001b[39mfeature_max, qualityLevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, minDistance\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\alloc.cpp:73: error: (-4:Insufficient memory) Failed to allocate 11059200 bytes in function 'cv::OutOfMemoryError'\n"
     ]
    }
   ],
   "source": [
    "frame_path = r\"C:\\Users\\simar\\OneDrive\\Desktop\\Python_stabilization\\unzipped_video\" # <-- Set this to your frame directory\n",
    "output_path = \"mesh_stabilized.mp4\"\n",
    "mesh_size = 16  # Mesh cell size in pixels (adjust as needed)\n",
    "feature_max = 400  # Max features per frame\n",
    "radius = 100  # Motion propagation radius (pixels)\n",
    "window_size = 15  # Smoothing window (frames)\n",
    "crop_margin = 30  # Cropping margin to remove border artifacts\n",
    "\n",
    "# --- LOAD FRAMES ---\n",
    "frame_files = sorted(glob(os.path.join(frame_path, \"*.jpg\")))\n",
    "frames = [cv2.imread(f) for f in frame_files]\n",
    "height, width = frames[0].shape[:2]\n",
    "\n",
    "# --- VIDEO WRITER ---\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, 30.0, (width - 2*crop_margin, height - 2*crop_margin))\n",
    "\n",
    "# --- MESH GRID ---\n",
    "rows = height // mesh_size\n",
    "cols = width // mesh_size\n",
    "\n",
    "def get_mesh_vertices():\n",
    "    yv, xv = np.meshgrid(np.arange(0, height, mesh_size), np.arange(0, width, mesh_size), indexing='ij')\n",
    "    return np.stack([xv, yv], axis=-1).reshape(-1, 2)\n",
    "\n",
    "mesh_vertices = get_mesh_vertices()\n",
    "\n",
    "# --- FEATURE DETECTOR ---\n",
    "def detect_features(gray):\n",
    "    return cv2.goodFeaturesToTrack(gray, maxCorners=feature_max, qualityLevel=0.01, minDistance=8)\n",
    "\n",
    "# --- MOTION PROPAGATION ---\n",
    "def mesh_motion(old_pts, new_pts, old_gray):\n",
    "    # Assign motion vectors to mesh vertices using median filtering\n",
    "    motion_vectors = np.zeros((rows, cols, 2), dtype=np.float32)\n",
    "    counts = np.zeros((rows, cols), dtype=np.int32)\n",
    "    for (p0, p1) in zip(old_pts, new_pts):\n",
    "        x, y = p0.ravel()\n",
    "        dx, dy = (p1 - p0).ravel()\n",
    "        i, j = int(y) // mesh_size, int(x) // mesh_size\n",
    "        if 0 <= i < rows and 0 <= j < cols:\n",
    "            motion_vectors[i, j] += [dx, dy]\n",
    "            counts[i, j] += 1\n",
    "    # Avoid division by zero\n",
    "    counts[counts == 0] = 1\n",
    "    motion_vectors /= counts[..., None]\n",
    "    # Median filter to suppress outliers (moving objects)\n",
    "    motion_vectors[...,0] = medfilt(motion_vectors[...,0], kernel_size=3)\n",
    "    motion_vectors[...,1] = medfilt(motion_vectors[...,1], kernel_size=3)\n",
    "    return motion_vectors\n",
    "\n",
    "# --- PATH SMOOTHING ---\n",
    "def smooth_path(path, radius=window_size):\n",
    "    smoothed = np.copy(path)\n",
    "    for i in range(path.shape[0]):\n",
    "        for j in range(path.shape[1]):\n",
    "            for d in range(2):\n",
    "                smoothed[i,j,:,d] = np.convolve(path[i,j,:,d], np.ones(radius)/radius, mode='same')\n",
    "    return smoothed\n",
    "\n",
    "# --- WARP FRAME WITH MESH ---\n",
    "def warp_frame_mesh(frame, mesh_flow):\n",
    "    map_x = np.zeros((height, width), dtype=np.float32)\n",
    "    map_y = np.zeros((height, width), dtype=np.float32)\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            dx, dy = mesh_flow[i, j]\n",
    "            y0 = i * mesh_size\n",
    "            x0 = j * mesh_size\n",
    "            y1 = min((i+1) * mesh_size, height)\n",
    "            x1 = min((j+1) * mesh_size, width)\n",
    "            map_x[y0:y1, x0:x1] = np.clip(np.arange(x0, x1)[None, :] + dx, 0, width-1)\n",
    "            map_y[y0:y1, x0:x1] = np.clip(np.arange(y0, y1)[:, None] + dy, 0, height-1)\n",
    "    return cv2.remap(frame, map_x, map_y, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)\n",
    "\n",
    "# --- MAIN PROCESS ---\n",
    "prev_gray = cv2.cvtColor(frames[0], cv2.COLOR_BGR2GRAY)\n",
    "prev_pts = detect_features(prev_gray)\n",
    "mesh_flows = []\n",
    "\n",
    "# Step 1: Estimate mesh flows between frames\n",
    "for i in tqdm(range(1, len(frames)), desc=\"Estimating mesh flows\"):\n",
    "    curr_gray = cv2.cvtColor(frames[i], cv2.COLOR_BGR2GRAY)\n",
    "    curr_pts, status, _ = cv2.calcOpticalFlowPyrLK(prev_gray, curr_gray, prev_pts, None)\n",
    "    good_prev = prev_pts[status.flatten()==1]\n",
    "    good_curr = curr_pts[status.flatten()==1]\n",
    "    mesh_flow = mesh_motion(good_prev, good_curr, prev_gray)\n",
    "    mesh_flows.append(mesh_flow)\n",
    "    prev_gray = curr_gray\n",
    "    prev_pts = detect_features(curr_gray)\n",
    "\n",
    "# Step 2: Accumulate and smooth mesh flows\n",
    "mesh_flows = [np.zeros_like(mesh_flows[0])] + mesh_flows  # First frame has zero motion\n",
    "mesh_paths = np.cumsum(mesh_flows, axis=0)  # Accumulate\n",
    "mesh_paths = np.stack(mesh_paths, axis=2)  # Shape: (rows, cols, frames, 2)\n",
    "mesh_paths = np.transpose(mesh_paths, (0,1,2,3))  # Ensure correct shape\n",
    "mesh_paths = smooth_path(mesh_paths)\n",
    "\n",
    "# Step 3: Warp and save stabilized frames\n",
    "for i, frame in tqdm(enumerate(frames), total=len(frames), desc=\"Warping and saving\"):\n",
    "    mesh_flow = mesh_paths[...,i,:]\n",
    "    stabilized = warp_frame_mesh(frame, mesh_flow)\n",
    "    # Crop borders to remove artifacts\n",
    "    stabilized = stabilized[crop_margin:height-crop_margin, crop_margin:width-crop_margin]\n",
    "    out.write(stabilized)\n",
    "\n",
    "out.release()\n",
    "print(\"Stabilized video saved to\", output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
