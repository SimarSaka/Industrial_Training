{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93a24754",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping opencv-python as it is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\simar\\anaconda3\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\simar\\anaconda3\\lib\\site-packages (from opencv-contrib-python) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall opencv-python -y\n",
    "!pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72c06f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.interpolate import UnivariateSpline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2c66836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_match_features(img1, img2, sift):\n",
    "    kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "    if des1 is None or des2 is None:\n",
    "        return np.array([]), np.array([])\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "    search_params = dict(checks=50)\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    matches = flann.knnMatch(des1, des2, k=2)\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.7 * n.distance:\n",
    "            good_matches.append(m)\n",
    "    if len(good_matches) < 4:\n",
    "        return np.array([]), np.array([])\n",
    "    pts1 = np.float32([kp1[m.queryIdx].pt for m in good_matches])\n",
    "    pts2 = np.float32([kp2[m.trainIdx].pt for m in good_matches])\n",
    "    return pts1, pts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09e250f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_homography(pts1, pts2):\n",
    "    if len(pts1) >= 4 and len(pts2) >= 4:\n",
    "        H, mask = cv2.findHomography(pts1, pts2, cv2.RANSAC, 5.0)\n",
    "        if H is None:\n",
    "            return np.eye(3)\n",
    "        return H\n",
    "    else:\n",
    "        return np.eye(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37b2d143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_trajectory(trajectory, smoothing_factor=5):\n",
    "    trajectory = np.array(trajectory)\n",
    "    smoothed = []\n",
    "    for i in range(trajectory.shape[1]):\n",
    "        x = np.arange(trajectory.shape[0])\n",
    "        y = trajectory[:, i]\n",
    "        spl = UnivariateSpline(x, y, s=smoothing_factor)\n",
    "        smoothed.append(spl(x))\n",
    "    return np.array(smoothed).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "510962bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input path received: DJI_20250411113208_0019_D.MP4\n"
     ]
    }
   ],
   "source": [
    "input_path = \"DJI_20250411113208_0019_D.MP4\"\n",
    "output_path =\"Blinestabilized_output.mp4\"\n",
    "\n",
    "streaming_video_stabilization(input_path, output_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c9597631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(input_path):\n",
    "    print(\"‚ùå File not found at:\", input_path)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f4d3400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def streaming_video_stabilization(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Streaming video stabilization that processes and writes frames one at a time\n",
    "    \"\"\"\n",
    "    # Open input video\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video\")\n",
    "        return\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    print(f\"Video info: {total_frames} frames, {w}x{h}, {fps:.2f} FPS\")\n",
    "    \n",
    "    # Setup output video\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (w, h))\n",
    "    \n",
    "    # Initialize SIFT detector\n",
    "    sift = cv2.SIFT_create()\n",
    "    \n",
    "    # Read first frame\n",
    "    ret, prev_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Could not read first frame\")\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        return\n",
    "    \n",
    "    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Initialize lists to store trajectory and transforms\n",
    "    transforms = []\n",
    "    trajectory = [np.eye(3)]\n",
    "    \n",
    "    frame_count = 1\n",
    "    print(\"Phase 1: Computing transforms...\")\n",
    "    \n",
    "    # Phase 1: Compute all transforms\n",
    "    while True:\n",
    "        ret, curr_frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        curr_gray = cv2.cvtColor(curr_frame, cv2.COLOR_BGR2GRAY)\n",
    "        pts1, pts2 = detect_and_match_features(prev_gray, curr_gray, sift)\n",
    "        H = estimate_homography(pts1, pts2)\n",
    "        transforms.append(H)\n",
    "        \n",
    "        # Build cumulative trajectory\n",
    "        trajectory.append(trajectory[-1] @ H)\n",
    "        \n",
    "        prev_gray = curr_gray\n",
    "        frame_count += 1\n",
    "        \n",
    "        if frame_count % 100 == 0:\n",
    "            print(f\"Processed {frame_count}/{total_frames} frames\")\n",
    "    \n",
    "    print(\"Phase 2: Smoothing trajectory...\")\n",
    "    \n",
    "    # Extract translation and rotation parameters\n",
    "    params = []\n",
    "    for H in trajectory:\n",
    "        dx = H[0, 2]\n",
    "        dy = H[1, 2]\n",
    "        da = np.arctan2(H[1, 0], H[0, 0])\n",
    "        params.append([dx, dy, da])\n",
    "    \n",
    "    # Smooth trajectory\n",
    "    smoothed_params = smooth_trajectory(params, smoothing_factor=10)\n",
    "    \n",
    "    # Calculate smoothed transforms\n",
    "    new_transforms = []\n",
    "    for i in range(len(smoothed_params)):\n",
    "        dx, dy, da = smoothed_params[i]\n",
    "        cos_a = np.cos(da)\n",
    "        sin_a = np.sin(da)\n",
    "        new_H = np.array([[cos_a, -sin_a, dx],\n",
    "                          [sin_a,  cos_a, dy],\n",
    "                          [0,      0,     1]], dtype=np.float32)\n",
    "        new_transforms.append(new_H)\n",
    "    \n",
    "    print(\"Phase 3: Applying stabilization and writing video...\")\n",
    "    \n",
    "    # Phase 2: Apply transforms and write stabilized video\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)  # Reset to beginning\n",
    "    \n",
    "    frame_idx = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Apply stabilization transform\n",
    "        if frame_idx < len(new_transforms):\n",
    "            H = new_transforms[frame_idx]\n",
    "            \n",
    "            # Validate transform matrix\n",
    "            if H is not None and not np.isnan(H).any() and not np.isinf(H).any():\n",
    "                try:\n",
    "                    frame_stabilized = cv2.warpPerspective(frame, H, (w, h), \n",
    "                                                         borderMode=cv2.BORDER_REFLECT)\n",
    "                except:\n",
    "                    frame_stabilized = frame\n",
    "            else:\n",
    "                frame_stabilized = frame\n",
    "        else:\n",
    "            frame_stabilized = frame\n",
    "        \n",
    "        # Write stabilized frame directly to output video\n",
    "        out.write(frame_stabilized)\n",
    "        \n",
    "        frame_idx += 1\n",
    "        if frame_idx % 100 == 0:\n",
    "            print(f\"Stabilized and wrote {frame_idx}/{total_frames} frames\")\n",
    "    \n",
    "    # Cleanup\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"Stabilized video saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9fbaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video info: 7170 frames, 3840x2160, 29.97 FPS\n",
      "Phase 1: Computing transforms...\n",
      "Processed 100/7170 frames\n",
      "Processed 200/7170 frames\n",
      "Processed 300/7170 frames\n",
      "Processed 400/7170 frames\n",
      "Processed 500/7170 frames\n",
      "Processed 600/7170 frames\n",
      "Processed 700/7170 frames\n",
      "Processed 800/7170 frames\n"
     ]
    }
   ],
   "source": [
    "input_path = \"DJI_20250411113208_0019_D.MP4\"\n",
    "output_path = \"Blinestabilized_streaming_output.mp4\"\n",
    "\n",
    "streaming_video_stabilization(input_path, output_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0543e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video info: 7170 frames, 3840x2160, 29.97 FPS\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006efacc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7390129b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba9440f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f415457",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
