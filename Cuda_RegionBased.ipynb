{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5119786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing frames...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 3958/7169 [6:54:47<5:36:30,  6.29s/it]\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\alloc.cpp:73: error: (-4:Insufficient memory) Failed to allocate 2764800 bytes in function 'cv::OutOfMemoryError'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 181\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    176\u001b[0m     stabilizer \u001b[38;5;241m=\u001b[39m AdvancedStabilizer(\n\u001b[0;32m    177\u001b[0m         frames_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msimar\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPython_stabilization\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124munzipped_video\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    178\u001b[0m         output_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msimar\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPython_stabilization\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcpu_optimized.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    179\u001b[0m         fps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m29.97\u001b[39m\n\u001b[0;32m    180\u001b[0m     )\n\u001b[1;32m--> 181\u001b[0m     stabilizer\u001b[38;5;241m.\u001b[39mstabilize()\n",
      "Cell \u001b[1;32mIn[26], line 117\u001b[0m, in \u001b[0;36mAdvancedStabilizer.stabilize\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    115\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe_files))):\n\u001b[1;32m--> 117\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_frame(i)\n\u001b[0;32m    118\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(result)\n\u001b[0;32m    120\u001b[0m valid_results \u001b[38;5;241m=\u001b[39m [r \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results \u001b[38;5;28;01mif\u001b[39;00m r[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n",
      "Cell \u001b[1;32mIn[26], line 76\u001b[0m, in \u001b[0;36mAdvancedStabilizer.process_frame\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_frame\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m---> 76\u001b[0m     frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe_files[idx])\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m frame \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\alloc.cpp:73: error: (-4:Insufficient memory) Failed to allocate 2764800 bytes in function 'cv::OutOfMemoryError'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from scipy.signal import savgol_filter\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms as T\n",
    "\n",
    "# --------------------- Lightweight Segmentation ---------------------\n",
    "class DynamicMaskGenerator:\n",
    "    def __init__(self):\n",
    "        self.model = models.segmentation.deeplabv3_mobilenet_v3_large(pretrained=True)\n",
    "        self.model = self.model.to('cpu').eval()\n",
    "        self.transform = T.Compose([\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "    def generate_mask(self, frame):\n",
    "        input_tensor = self.transform(frame).unsqueeze(0).to('cpu')\n",
    "        with torch.no_grad():\n",
    "            output = self.model(input_tensor)['out'][0]\n",
    "        output = output.argmax(0).cpu().numpy()\n",
    "        # Adjust these indices based on your model's class mapping\n",
    "        dynamic_mask = np.isin(output, [1, 2, 3])  # Example: people, vehicles, plants\n",
    "        return dynamic_mask.astype(np.uint8) * 255\n",
    "\n",
    "# --------------------- Robust Feature Handling ---------------------\n",
    "class FeatureManager:\n",
    "    def __init__(self):\n",
    "        self.detectors = {\n",
    "            'fast': cv2.FastFeatureDetector_create(threshold=50),\n",
    "            'gftt': cv2.GFTTDetector_create(maxCorners=800, qualityLevel=0.02),\n",
    "            'orb': cv2.ORB_create(nfeatures=1500, fastThreshold=20)\n",
    "        }\n",
    "        self.matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)\n",
    "\n",
    "    def detect_features(self, gray):\n",
    "        features = []\n",
    "        for name, det in self.detectors.items():\n",
    "            kp = det.detect(gray, None)\n",
    "            if name == 'orb':\n",
    "                kp, des = det.compute(gray, kp)\n",
    "            else:\n",
    "                des = None\n",
    "            features.append((kp, des))\n",
    "        return features\n",
    "\n",
    "    def match_features(self, des1, des2, ratio=0.75):\n",
    "        if des1 is None or des2 is None or len(des1) < 2 or len(des2) < 2:\n",
    "            return []\n",
    "        matches = self.matcher.knnMatch(des1, des2, k=2)\n",
    "        return [m[0] for m in matches if len(m) == 2 and m[0].distance < ratio * m[1].distance]\n",
    "\n",
    "# --------------------- CPU-Optimized Stabilization ---------------------\n",
    "class AdvancedStabilizer:\n",
    "    def __init__(self, frames_path, output_path, fps=30):\n",
    "        self.frames_path = frames_path\n",
    "        self.output_path = output_path\n",
    "        self.fps = fps\n",
    "        self.mask_generator = DynamicMaskGenerator()\n",
    "        self.feature_mgr = FeatureManager()\n",
    "        \n",
    "        # Load frames with numeric sorting\n",
    "        self.frame_files = sorted(\n",
    "            [os.path.join(frames_path, f) for f in os.listdir(frames_path) \n",
    "             if f.lower().endswith(('.png','.jpg','.jpeg'))],\n",
    "            key=lambda x: int(''.join(filter(str.isdigit, os.path.basename(x)))) if ''.join(filter(str.isdigit, os.path.basename(x))) else 0\n",
    "        )\n",
    "        \n",
    "        if not self.frame_files:\n",
    "            raise ValueError(\"No valid image files found\")\n",
    "\n",
    "    def process_frame(self, idx):\n",
    "        frame = cv2.imread(self.frame_files[idx])\n",
    "        if frame is None:\n",
    "            return None, None, None\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        mask = self.mask_generator.generate_mask(frame)\n",
    "        return gray, mask, frame\n",
    "\n",
    "    def compute_transform(self, prev_gray, curr_gray, mask):\n",
    "        prev_feats = self.feature_mgr.detect_features(prev_gray)\n",
    "        curr_feats = self.feature_mgr.detect_features(curr_gray)\n",
    "        \n",
    "        matches = []\n",
    "        for (kp1, des1), (kp2, des2) in zip(prev_feats, curr_feats):\n",
    "            if des1 is not None and des2 is not None:\n",
    "                matches.extend(self.feature_mgr.match_features(des1, des2))\n",
    "        \n",
    "        if len(matches) > 4:\n",
    "            pts1 = np.float32([prev_feats[0][0][m.queryIdx].pt for m in matches])\n",
    "            pts2 = np.float32([curr_feats[0][0][m.trainIdx].pt for m in matches])\n",
    "            \n",
    "            # Enhanced validation with border check\n",
    "            h, w = mask.shape\n",
    "            valid = [\n",
    "                mask[int(y), int(x)] == 0 and\n",
    "                20 < x < w-20 and 20 < y < h-20\n",
    "                for x, y in pts1\n",
    "            ]\n",
    "            pts1 = pts1[valid]\n",
    "            pts2 = pts2[valid]\n",
    "            \n",
    "            if len(pts1) >= 4:\n",
    "                H, _ = cv2.estimateAffinePartial2D(pts1, pts2, method=cv2.RANSAC, \n",
    "                                                 ransacReprojThreshold=4.0)\n",
    "                return H if H is not None else np.eye(3)[:2]\n",
    "        return np.eye(3)[:2]\n",
    "\n",
    "    def stabilize(self):\n",
    "        # Sequential frame loading and preprocessing (NO MULTIPROCESSING)\n",
    "        print(\"Loading and preprocessing frames...\")\n",
    "        results = []\n",
    "        for i in tqdm(range(len(self.frame_files))):\n",
    "            result = self.process_frame(i)\n",
    "            results.append(result)\n",
    "        \n",
    "        valid_results = [r for r in results if r[0] is not None]\n",
    "        if not valid_results:\n",
    "            raise ValueError(\"No frames could be processed\")\n",
    "            \n",
    "        self.gray_frames, self.masks, self.frames = zip(*valid_results)\n",
    "        \n",
    "        # Compute motion transforms\n",
    "        print(\"Computing transforms...\")\n",
    "        transforms = [np.eye(3)[:2]]\n",
    "        for i in tqdm(range(1, len(self.gray_frames))):\n",
    "            H = self.compute_transform(self.gray_frames[i-1], self.gray_frames[i], self.masks[i])\n",
    "            transforms.append(H)\n",
    "        \n",
    "        # Smoothing with Savitzky-Golay filter with proper window handling\n",
    "        print(\"Optimizing trajectory...\")\n",
    "        params = np.array([t.flatten() for t in transforms])\n",
    "        n_frames = params.shape[0]\n",
    "        \n",
    "        # Dynamic window length handling\n",
    "        window_length = min(15, n_frames)\n",
    "        if window_length % 2 == 0:  # Must be odd\n",
    "            window_length = max(3, window_length - 1)\n",
    "        if window_length < 3:\n",
    "            window_length = 3\n",
    "        \n",
    "        smoothed_params = savgol_filter(params.T, window_length=window_length, polyorder=2, axis=1).T\n",
    "        \n",
    "        # Prepare stabilized video\n",
    "        print(\"Writing output...\")\n",
    "        h, w = self.frames[0].shape[:2]\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(self.output_path, fourcc, self.fps, (w, h))\n",
    "        \n",
    "        if not out.isOpened():\n",
    "            raise RuntimeError(\"Could not initialize video writer\")\n",
    "        \n",
    "        for i in tqdm(range(len(self.frames))):\n",
    "            if i < len(smoothed_params):\n",
    "                try:\n",
    "                    # Reshape flattened parameters to 2x3 matrix\n",
    "                    H_flat = smoothed_params[i]\n",
    "                    H = H_flat.reshape(2, 3)\n",
    "                    stabilized = cv2.warpAffine(self.frames[i], H, (w, h), \n",
    "                                              borderMode=cv2.BORDER_REFLECT)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error warping frame {i}: {e}\")\n",
    "                    stabilized = self.frames[i]\n",
    "            else:\n",
    "                stabilized = self.frames[i]\n",
    "            out.write(stabilized)\n",
    "        \n",
    "        out.release()\n",
    "        print(f\"Stabilized video saved to: {self.output_path}\")\n",
    "\n",
    "# --------------------- Usage ---------------------\n",
    "if __name__ == \"__main__\":\n",
    "    stabilizer = AdvancedStabilizer(\n",
    "        frames_path=r\"C:\\Users\\simar\\OneDrive\\Desktop\\Python_stabilization\\unzipped_video\",\n",
    "        output_path=r\"C:\\Users\\simar\\OneDrive\\Desktop\\Python_stabilization\\cpu_optimized.mp4\",\n",
    "        fps=29.97\n",
    "    )\n",
    "    stabilizer.stabilize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556e580f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
