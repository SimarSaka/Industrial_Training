{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2d55f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_path = r\"C:\\Users\\simar\\OneDrive\\Desktop\\Python_stabilization\\unzipped_video\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a54d470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: opencv-python\n",
      "Version: 4.11.0.86\n",
      "Summary: Wrapper package for OpenCV python bindings.\n",
      "Home-page: https://github.com/opencv/opencv-python\n",
      "Author: \n",
      "Author-email: \n",
      "License: Apache 2.0\n",
      "Location: C:\\Users\\simar\\anaconda3\\Lib\\site-packages\n",
      "Requires: numpy, numpy, numpy, numpy, numpy\n",
      "Required-by: \n",
      "---\n",
      "Name: tqdm\n",
      "Version: 4.65.0\n",
      "Summary: Fast, Extensible Progress Meter\n",
      "Home-page: https://tqdm.github.io\n",
      "Author: \n",
      "Author-email: \n",
      "License: MPLv2.0, MIT Licences\n",
      "Location: C:\\Users\\simar\\anaconda3\\Lib\\site-packages\n",
      "Requires: colorama\n",
      "Required-by: anaconda-client, anaconda-project, conda, conda-build, gdown, nltk, openai, panel\n",
      "---\n",
      "Name: matplotlib\n",
      "Version: 3.8.0\n",
      "Summary: Python plotting package\n",
      "Home-page: https://matplotlib.org\n",
      "Author: John D. Hunter, Michael Droettboom\n",
      "Author-email: matplotlib-users@python.org\n",
      "License: PSF\n",
      "Location: C:\\Users\\simar\\anaconda3\\Lib\\site-packages\n",
      "Requires: contourpy, cycler, fonttools, kiwisolver, numpy, packaging, pillow, pyparsing, python-dateutil\n",
      "Required-by: seaborn\n"
     ]
    }
   ],
   "source": [
    "!pip show opencv-python tqdm matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcebde0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40cdb647",
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv2.SIFT_create()\n",
    "bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "\n",
    "frames = sorted(os.listdir(frames_path))\n",
    "frame_paths = [os.path.join(frames_path, f) for f in frames]\n",
    "affine_transforms = []\n",
    "\n",
    "for i in range(len(frame_paths) - 1):\n",
    "    img1 = cv2.imread(frame_paths[i], cv2.IMREAD_GRAYSCALE)\n",
    "    img2 = cv2.imread(frame_paths[i + 1], cv2.IMREAD_GRAYSCALE)\n",
    "    if img1 is None or img2 is None:\n",
    "        continue\n",
    "    kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "    if des1 is None or des2 is None or len(kp1) < 4 or len(kp2) < 4:\n",
    "        continue\n",
    "    matches = bf.match(des1, des2)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "    pts1 = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    pts2 = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    if len(pts1) < 4:\n",
    "        continue\n",
    "    affine, _ = cv2.estimateAffinePartial2D(pts1, pts2)\n",
    "    if affine is not None:\n",
    "        affine_transforms.append(affine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56dfedb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KalmanFilter1D:\n",
    "    def __init__(self, process_variance=1e-3, measurement_variance=1e-1):\n",
    "        self.process_variance = process_variance\n",
    "        self.measurement_variance = measurement_variance\n",
    "        self.posteri_estimate = 0\n",
    "        self.posteri_error_estimate = 1.0\n",
    "\n",
    "    def filter(self, measurements):\n",
    "        estimates = []\n",
    "        for measurement in measurements:\n",
    "            prior = self.posteri_estimate\n",
    "            prior_err = self.posteri_error_estimate + self.process_variance\n",
    "            K = prior_err / (prior_err + self.measurement_variance)\n",
    "            self.posteri_estimate = prior + K * (measurement - prior)\n",
    "            self.posteri_error_estimate = (1 - K) * prior_err\n",
    "            estimates.append(self.posteri_estimate)\n",
    "        return np.array(estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bc4d972",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = [t[0, 2] for t in affine_transforms]\n",
    "dy = [t[1, 2] for t in affine_transforms]\n",
    "kf_x, kf_y = KalmanFilter1D(), KalmanFilter1D()\n",
    "dx_smooth, dy_smooth = kf_x.filter(dx), kf_y.filter(dy)\n",
    "\n",
    "smoothed_transforms = []\n",
    "for i, affine in enumerate(affine_transforms):\n",
    "    smoothed = affine.copy()\n",
    "    smoothed[0, 2], smoothed[1, 2] = dx_smooth[i], dy_smooth[i]\n",
    "    smoothed_transforms.append(smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "960aa553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video FPS: 29.97002997002997\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e1b8b83200f447d9be268e9a6b4950d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7168 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "video_name = r\"C:\\Users\\simar\\OneDrive\\Desktop\\Python_stabilization\\DJI_20250411113208_0019_D.MP4\"\n",
    "cap = cv2.VideoCapture(video_name)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "print(f\"Video FPS: {fps}\")\n",
    "\n",
    "sample_frame = cv2.imread(frame_paths[0])\n",
    "h, w = sample_frame.shape[:2]\n",
    "out_path = \"19VSstabilized_output_sift.mp4\"\n",
    "out = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))\n",
    "\n",
    "for i in tqdm(range(len(smoothed_transforms))):\n",
    "    frame = cv2.imread(frame_paths[i])\n",
    "    if frame is None:\n",
    "        continue\n",
    "    M = smoothed_transforms[i]\n",
    "    stabilized = cv2.warpAffine(frame, M, (w, h))\n",
    "    out.write(stabilized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac669c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stabilized video saved as: 19VSstabilized_output_sift.mp4\n"
     ]
    }
   ],
   "source": [
    "last_frame = cv2.imread(frame_paths[-1])\n",
    "if last_frame is not None:\n",
    "    out.write(last_frame)\n",
    "\n",
    "out.release()\n",
    "print(\"Stabilized video saved as:\", out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c9d2f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
